W&B run initialized: genial-surf-32
W&B project URL: https://wandb.ai/s-sueron-eindhoven-university-of-technology/vegfr2-cnn/runs/xx6992ue
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_88' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
Epoch 1/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 2.6100 - root_mean_squared_error: 1.6155 - val_loss: 2.5679 - val_root_mean_squared_error: 1.6025
Epoch 2/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.2059 - root_mean_squared_error: 1.0981 - val_loss: 2.0987 - val_root_mean_squared_error: 1.4487
Epoch 3/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1024 - root_mean_squared_error: 1.0500 - val_loss: 1.3957 - val_root_mean_squared_error: 1.1814
Epoch 4/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.0199 - root_mean_squared_error: 1.0099 - val_loss: 3.1497 - val_root_mean_squared_error: 1.7747
Epoch 5/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.9606 - root_mean_squared_error: 0.9801 - val_loss: 2.2328 - val_root_mean_squared_error: 1.4943
Epoch 6/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8558 - root_mean_squared_error: 0.9251 - val_loss: 1.4547 - val_root_mean_squared_error: 1.2061
Epoch 7/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8038 - root_mean_squared_error: 0.8965 - val_loss: 2.0323 - val_root_mean_squared_error: 1.4256
Epoch 8/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - loss: 0.7811 - root_mean_squared_error: 0.8838 - val_loss: 1.9527 - val_root_mean_squared_error: 1.3974
Epoch 9/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - loss: 0.7611 - root_mean_squared_error: 0.8724 - val_loss: 2.4684 - val_root_mean_squared_error: 1.5711
Epoch 10/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.6620 - root_mean_squared_error: 0.8136 - val_loss: 2.5990 - val_root_mean_squared_error: 1.6121
Epoch 11/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.6197 - root_mean_squared_error: 0.7872 - val_loss: 2.7554 - val_root_mean_squared_error: 1.6599
Epoch 12/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.6567 - root_mean_squared_error: 0.8104 - val_loss: 2.1429 - val_root_mean_squared_error: 1.4639
Epoch 13/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.5844 - root_mean_squared_error: 0.7645 - val_loss: 2.1092 - val_root_mean_squared_error: 1.4523
Epoch 14/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.5807 - root_mean_squared_error: 0.7620 - val_loss: 1.9666 - val_root_mean_squared_error: 1.4023
Epoch 15/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 5ms/step - loss: 0.5692 - root_mean_squared_error: 0.7544 - val_loss: 2.2527 - val_root_mean_squared_error: 1.5009
Epoch 16/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.5235 - root_mean_squared_error: 0.7235 - val_loss: 2.7743 - val_root_mean_squared_error: 1.6656
Epoch 17/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.5316 - root_mean_squared_error: 0.7291 - val_loss: 1.6254 - val_root_mean_squared_error: 1.2749
Epoch 18/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.5170 - root_mean_squared_error: 0.7191 - val_loss: 2.3238 - val_root_mean_squared_error: 1.5244
Epoch 19/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4671 - root_mean_squared_error: 0.6835 - val_loss: 2.3020 - val_root_mean_squared_error: 1.5172
Epoch 20/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4598 - root_mean_squared_error: 0.6781 - val_loss: 2.3129 - val_root_mean_squared_error: 1.5208
Epoch 21/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4580 - root_mean_squared_error: 0.6768 - val_loss: 2.4890 - val_root_mean_squared_error: 1.5777
Epoch 22/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4846 - root_mean_squared_error: 0.6961 - val_loss: 3.3948 - val_root_mean_squared_error: 1.8425
Epoch 23/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4078 - root_mean_squared_error: 0.6386 - val_loss: 1.6664 - val_root_mean_squared_error: 1.2909
Epoch 24/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4127 - root_mean_squared_error: 0.6424 - val_loss: 2.7112 - val_root_mean_squared_error: 1.6466
Epoch 25/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4222 - root_mean_squared_error: 0.6498 - val_loss: 1.7981 - val_root_mean_squared_error: 1.3409
Epoch 26/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4010 - root_mean_squared_error: 0.6332 - val_loss: 1.8176 - val_root_mean_squared_error: 1.3482
Epoch 27/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.4125 - root_mean_squared_error: 0.6423 - val_loss: 3.3365 - val_root_mean_squared_error: 1.8266
Epoch 28/300
[1m150/150[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.3924 - root_mean_squared_error: 0.6264 - val_loss: 1.7307 - val_root_mean_squared_error: 1.3156
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_88' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
[1m16/16[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 2ms/step
