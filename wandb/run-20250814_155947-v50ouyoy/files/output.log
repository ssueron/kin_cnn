W&B run initialized: pleasant-capybara-32
W&B project URL: https://wandb.ai/s-sueron-eindhoven-university-of-technology/vegfr2-cnn/runs/v50ouyoy
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_104' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
Epoch 1/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 5ms/step - loss: 8.6173 - root_mean_squared_error: 2.9355 - val_loss: 8.5732 - val_root_mean_squared_error: 2.9280
Epoch 2/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.4509 - root_mean_squared_error: 1.2045 - val_loss: 8.1756 - val_root_mean_squared_error: 2.8593
Epoch 3/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 5ms/step - loss: 1.3449 - root_mean_squared_error: 1.1597 - val_loss: 7.6504 - val_root_mean_squared_error: 2.7659
Epoch 4/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 5ms/step - loss: 1.2970 - root_mean_squared_error: 1.1388 - val_loss: 6.1957 - val_root_mean_squared_error: 2.4891
Epoch 5/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.2307 - root_mean_squared_error: 1.1094 - val_loss: 7.4438 - val_root_mean_squared_error: 2.7283
Epoch 6/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.2444 - root_mean_squared_error: 1.1155 - val_loss: 7.5733 - val_root_mean_squared_error: 2.7520
Epoch 7/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.1360 - root_mean_squared_error: 1.0658 - val_loss: 7.2380 - val_root_mean_squared_error: 2.6903
Epoch 8/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 5ms/step - loss: 1.1019 - root_mean_squared_error: 1.0497 - val_loss: 5.2091 - val_root_mean_squared_error: 2.2823
Epoch 9/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.1720 - root_mean_squared_error: 1.0826 - val_loss: 6.0369 - val_root_mean_squared_error: 2.4570
Epoch 10/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.1172 - root_mean_squared_error: 1.0570 - val_loss: 6.8456 - val_root_mean_squared_error: 2.6164
Epoch 11/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.0280 - root_mean_squared_error: 1.0139 - val_loss: 6.3143 - val_root_mean_squared_error: 2.5128
Epoch 12/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 1.0150 - root_mean_squared_error: 1.0075 - val_loss: 5.8977 - val_root_mean_squared_error: 2.4285
Epoch 13/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.9732 - root_mean_squared_error: 0.9865 - val_loss: 5.9734 - val_root_mean_squared_error: 2.4441
Epoch 14/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.9688 - root_mean_squared_error: 0.9843 - val_loss: 6.2623 - val_root_mean_squared_error: 2.5024
Epoch 15/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.9365 - root_mean_squared_error: 0.9677 - val_loss: 5.8766 - val_root_mean_squared_error: 2.4242
Epoch 16/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.9990 - root_mean_squared_error: 0.9995 - val_loss: 4.9791 - val_root_mean_squared_error: 2.2314
Epoch 17/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.9253 - root_mean_squared_error: 0.9619 - val_loss: 5.8941 - val_root_mean_squared_error: 2.4278
Epoch 18/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8808 - root_mean_squared_error: 0.9385 - val_loss: 5.2706 - val_root_mean_squared_error: 2.2958
Epoch 19/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8956 - root_mean_squared_error: 0.9464 - val_loss: 5.7461 - val_root_mean_squared_error: 2.3971
Epoch 20/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 5ms/step - loss: 0.9221 - root_mean_squared_error: 0.9603 - val_loss: 5.5864 - val_root_mean_squared_error: 2.3635
Epoch 21/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8740 - root_mean_squared_error: 0.9349 - val_loss: 5.9529 - val_root_mean_squared_error: 2.4399
Epoch 22/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.9003 - root_mean_squared_error: 0.9488 - val_loss: 5.4632 - val_root_mean_squared_error: 2.3373
Epoch 23/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8277 - root_mean_squared_error: 0.9098 - val_loss: 5.3630 - val_root_mean_squared_error: 2.3158
Epoch 24/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8329 - root_mean_squared_error: 0.9127 - val_loss: 5.1449 - val_root_mean_squared_error: 2.2682
Epoch 25/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8149 - root_mean_squared_error: 0.9027 - val_loss: 5.7349 - val_root_mean_squared_error: 2.3948
Epoch 26/150
[1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step - loss: 0.8027 - root_mean_squared_error: 0.8959 - val_loss: 5.6261 - val_root_mean_squared_error: 2.3719
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_104' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 2ms/step
