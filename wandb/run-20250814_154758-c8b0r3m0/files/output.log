W&B run initialized: generous-river-9
W&B project URL: https://wandb.ai/s-sueron-eindhoven-university-of-technology/vegfr2-cnn/runs/c8b0r3m0
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_32' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
Epoch 1/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 5.2569 - root_mean_squared_error: 2.2928 - val_loss: 14.7856 - val_root_mean_squared_error: 3.8452
Epoch 2/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 2.4169 - root_mean_squared_error: 1.5546 - val_loss: 1.4040 - val_root_mean_squared_error: 1.1849
Epoch 3/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.5368 - root_mean_squared_error: 1.2397 - val_loss: 1.3637 - val_root_mean_squared_error: 1.1678
Epoch 4/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.3479 - root_mean_squared_error: 1.1610 - val_loss: 1.3543 - val_root_mean_squared_error: 1.1637
Epoch 5/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1977 - root_mean_squared_error: 1.0944 - val_loss: 1.3605 - val_root_mean_squared_error: 1.1664
Epoch 6/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1679 - root_mean_squared_error: 1.0807 - val_loss: 1.4165 - val_root_mean_squared_error: 1.1901
Epoch 7/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1284 - root_mean_squared_error: 1.0623 - val_loss: 1.4931 - val_root_mean_squared_error: 1.2219
Epoch 8/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1506 - root_mean_squared_error: 1.0727 - val_loss: 1.6274 - val_root_mean_squared_error: 1.2757
Epoch 9/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1792 - root_mean_squared_error: 1.0859 - val_loss: 2.0086 - val_root_mean_squared_error: 1.4173
Epoch 10/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1822 - root_mean_squared_error: 1.0873 - val_loss: 1.6061 - val_root_mean_squared_error: 1.2673
Epoch 11/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1836 - root_mean_squared_error: 1.0879 - val_loss: 1.5139 - val_root_mean_squared_error: 1.2304
Epoch 12/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1833 - root_mean_squared_error: 1.0878 - val_loss: 1.9136 - val_root_mean_squared_error: 1.3833
Epoch 13/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1850 - root_mean_squared_error: 1.0886 - val_loss: 1.3964 - val_root_mean_squared_error: 1.1817
Epoch 14/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1973 - root_mean_squared_error: 1.0942 - val_loss: 1.5063 - val_root_mean_squared_error: 1.2273
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_32' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 2ms/step
