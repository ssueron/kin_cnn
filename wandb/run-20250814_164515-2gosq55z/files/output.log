W&B run initialized: classic-butterfly-22
W&B project URL: https://wandb.ai/s-sueron-eindhoven-university-of-technology/vegfr2-cnn/runs/2gosq55z
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_63' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
Epoch 1/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 4.8119 - root_mean_squared_error: 2.1936 - val_loss: 24.4411 - val_root_mean_squared_error: 4.9438
Epoch 2/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 3.0955 - root_mean_squared_error: 1.7594 - val_loss: 18.2842 - val_root_mean_squared_error: 4.2760
Epoch 3/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 2.0980 - root_mean_squared_error: 1.4485 - val_loss: 1.6675 - val_root_mean_squared_error: 1.2913
Epoch 4/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.4634 - root_mean_squared_error: 1.2097 - val_loss: 1.3794 - val_root_mean_squared_error: 1.1745
Epoch 5/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.3587 - root_mean_squared_error: 1.1656 - val_loss: 1.4087 - val_root_mean_squared_error: 1.1869
Epoch 6/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.2693 - root_mean_squared_error: 1.1266 - val_loss: 1.4201 - val_root_mean_squared_error: 1.1917
Epoch 7/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.2306 - root_mean_squared_error: 1.1093 - val_loss: 1.5887 - val_root_mean_squared_error: 1.2604
Epoch 8/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.2044 - root_mean_squared_error: 1.0975 - val_loss: 1.5673 - val_root_mean_squared_error: 1.2519
Epoch 9/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1896 - root_mean_squared_error: 1.0907 - val_loss: 1.7175 - val_root_mean_squared_error: 1.3105
Epoch 10/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1686 - root_mean_squared_error: 1.0810 - val_loss: 1.6756 - val_root_mean_squared_error: 1.2945
Epoch 11/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1836 - root_mean_squared_error: 1.0879 - val_loss: 1.7609 - val_root_mean_squared_error: 1.3270
Epoch 12/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1703 - root_mean_squared_error: 1.0818 - val_loss: 1.6899 - val_root_mean_squared_error: 1.3000
Epoch 13/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1793 - root_mean_squared_error: 1.0859 - val_loss: 1.7824 - val_root_mean_squared_error: 1.3351
Epoch 14/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1755 - root_mean_squared_error: 1.0842 - val_loss: 1.7227 - val_root_mean_squared_error: 1.3125
Epoch 15/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1707 - root_mean_squared_error: 1.0820 - val_loss: 2.0937 - val_root_mean_squared_error: 1.4470
Epoch 16/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1813 - root_mean_squared_error: 1.0869 - val_loss: 1.7049 - val_root_mean_squared_error: 1.3057
Epoch 17/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1823 - root_mean_squared_error: 1.0873 - val_loss: 1.4828 - val_root_mean_squared_error: 1.2177
Epoch 18/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1778 - root_mean_squared_error: 1.0853 - val_loss: 1.5343 - val_root_mean_squared_error: 1.2387
Epoch 19/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1742 - root_mean_squared_error: 1.0836 - val_loss: 1.7510 - val_root_mean_squared_error: 1.3233
Epoch 20/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1712 - root_mean_squared_error: 1.0822 - val_loss: 1.4828 - val_root_mean_squared_error: 1.2177
Epoch 21/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1749 - root_mean_squared_error: 1.0839 - val_loss: 2.0213 - val_root_mean_squared_error: 1.4217
Epoch 22/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1794 - root_mean_squared_error: 1.0860 - val_loss: 1.8287 - val_root_mean_squared_error: 1.3523
Epoch 23/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.2151 - root_mean_squared_error: 1.1023 - val_loss: 1.8506 - val_root_mean_squared_error: 1.3604
Epoch 24/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1791 - root_mean_squared_error: 1.0859 - val_loss: 1.7780 - val_root_mean_squared_error: 1.3334
Epoch 25/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1750 - root_mean_squared_error: 1.0840 - val_loss: 1.6529 - val_root_mean_squared_error: 1.2856
Epoch 26/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1780 - root_mean_squared_error: 1.0854 - val_loss: 1.8244 - val_root_mean_squared_error: 1.3507
Epoch 27/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1697 - root_mean_squared_error: 1.0815 - val_loss: 1.6911 - val_root_mean_squared_error: 1.3004
Epoch 28/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1722 - root_mean_squared_error: 1.0827 - val_loss: 1.7839 - val_root_mean_squared_error: 1.3356
Epoch 29/300
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1767 - root_mean_squared_error: 1.0848 - val_loss: 1.5525 - val_root_mean_squared_error: 1.2460
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_63' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 2ms/step
