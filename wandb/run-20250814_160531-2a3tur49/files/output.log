W&B run initialized: pleasant-energy-41
W&B project URL: https://wandb.ai/s-sueron-eindhoven-university-of-technology/vegfr2-cnn/runs/2a3tur49
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_128' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
Epoch 1/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 11.1255 - root_mean_squared_error: 3.3355 - val_loss: 1.8976 - val_root_mean_squared_error: 1.3775
Epoch 2/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.2263 - root_mean_squared_error: 1.1074 - val_loss: 1.7049 - val_root_mean_squared_error: 1.3057
Epoch 3/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1630 - root_mean_squared_error: 1.0784 - val_loss: 1.8169 - val_root_mean_squared_error: 1.3479
Epoch 4/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.1247 - root_mean_squared_error: 1.0605 - val_loss: 1.9409 - val_root_mean_squared_error: 1.3932
Epoch 5/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.0705 - root_mean_squared_error: 1.0346 - val_loss: 1.7618 - val_root_mean_squared_error: 1.3273
Epoch 6/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.0655 - root_mean_squared_error: 1.0323 - val_loss: 1.6205 - val_root_mean_squared_error: 1.2730
Epoch 7/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.0191 - root_mean_squared_error: 1.0095 - val_loss: 1.8051 - val_root_mean_squared_error: 1.3436
Epoch 8/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 1.0066 - root_mean_squared_error: 1.0033 - val_loss: 1.6867 - val_root_mean_squared_error: 1.2987
Epoch 9/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.9714 - root_mean_squared_error: 0.9856 - val_loss: 1.9682 - val_root_mean_squared_error: 1.4029
Epoch 10/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.9424 - root_mean_squared_error: 0.9708 - val_loss: 1.5631 - val_root_mean_squared_error: 1.2502
Epoch 11/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.9112 - root_mean_squared_error: 0.9545 - val_loss: 1.9128 - val_root_mean_squared_error: 1.3831
Epoch 12/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.9099 - root_mean_squared_error: 0.9539 - val_loss: 1.2856 - val_root_mean_squared_error: 1.1339
Epoch 13/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8803 - root_mean_squared_error: 0.9382 - val_loss: 1.6661 - val_root_mean_squared_error: 1.2908
Epoch 14/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8402 - root_mean_squared_error: 0.9166 - val_loss: 1.6811 - val_root_mean_squared_error: 1.2966
Epoch 15/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8365 - root_mean_squared_error: 0.9146 - val_loss: 1.6627 - val_root_mean_squared_error: 1.2895
Epoch 16/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8128 - root_mean_squared_error: 0.9016 - val_loss: 1.7210 - val_root_mean_squared_error: 1.3119
Epoch 17/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.8057 - root_mean_squared_error: 0.8976 - val_loss: 1.9499 - val_root_mean_squared_error: 1.3964
Epoch 18/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.7857 - root_mean_squared_error: 0.8864 - val_loss: 1.7150 - val_root_mean_squared_error: 1.3096
Epoch 19/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.7713 - root_mean_squared_error: 0.8782 - val_loss: 1.6522 - val_root_mean_squared_error: 1.2854
Epoch 20/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.7409 - root_mean_squared_error: 0.8607 - val_loss: 1.9295 - val_root_mean_squared_error: 1.3891
Epoch 21/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.7431 - root_mean_squared_error: 0.8620 - val_loss: 1.9333 - val_root_mean_squared_error: 1.3904
Epoch 22/150
[1m300/300[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 4ms/step - loss: 0.7155 - root_mean_squared_error: 0.8459 - val_loss: 2.0503 - val_root_mean_squared_error: 1.4319
/home/postdoc/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_128' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 2ms/step
