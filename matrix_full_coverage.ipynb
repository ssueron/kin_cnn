{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a92cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "chembl = pd.read_csv('datasets/chembl_pretraining.csv')\n",
    "pkis2  = pd.read_csv('datasets/pkis2_finetuning.csv')\n",
    "chembl['__ds__'] = 'chembl_pretraining'\n",
    "pkis2['__ds__']  = 'pkis2_finetuning'\n",
    "dfu = pd.concat([chembl, pkis2], ignore_index=True)\n",
    "smiles = dfu['smiles'].tolist()\n",
    "prot_cols = [c for c in dfu.columns if c not in ['smiles','__ds__']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bb64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm_scaf(s):\n",
    "    if not isinstance(s, str):\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    if m is None:\n",
    "        return None\n",
    "    sc = MurckoScaffold.GetScaffoldForMol(m)\n",
    "    if sc is None or sc.GetNumAtoms() == 0:\n",
    "        return None\n",
    "    return Chem.MolToSmiles(sc, isomericSmiles=False)\n",
    "\n",
    "dfu['scaffold_smiles'] = dfu['smiles'].map(bm_scaf)\n",
    "scaf_id, scaf_vocab = pd.factorize(dfu['scaffold_smiles'], sort=True)\n",
    "dfu['scaf_id'] = scaf_id\n",
    "\n",
    "mols = [Chem.MolFromSmiles(s.strip()) if isinstance(s, str) and s.strip() else None\n",
    "        for s in dfu['smiles'].tolist()]\n",
    "\n",
    "grp = dfu.groupby('scaf_id').indices\n",
    "scaff_to_idx = {k: np.array(v, dtype=int) for k, v in grp.items() if k >= 0}\n",
    "rep_idx = [v[0] for v in scaff_to_idx.values()]\n",
    "\n",
    "gen = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=2048)\n",
    "X = np.zeros((len(rep_idx), 2048), dtype=bool)\n",
    "for r, i in enumerate(rep_idx):\n",
    "    m = mols[i]\n",
    "    if m is None:\n",
    "        continue\n",
    "    bv = gen.GetFingerprint(m)\n",
    "    on = list(bv.GetOnBits())\n",
    "    if on:\n",
    "        X[r, on] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2612152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_AB(A, B, chunk=2048):\n",
    "    B_u16 = B.astype(np.uint16); B_t = B_u16.T\n",
    "    bsum = B.sum(axis=1).astype(np.int32)\n",
    "    n = A.shape[0]\n",
    "    out = np.empty((n, B.shape[0]), dtype=np.float32)\n",
    "    for i in range(0, n, chunk):\n",
    "        Ab = A[i:i+chunk]\n",
    "        inter = Ab.astype(np.uint16) @ B_t\n",
    "        asum = Ab.sum(axis=1).astype(np.int32)[:, None]\n",
    "        union = asum + bsum[None, :] - inter\n",
    "        union = np.maximum(union, 1)\n",
    "        out[i:i+chunk] = inter / union\n",
    "    return out\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "n = X.shape[0]\n",
    "m = min(1024, n)\n",
    "L = rng.choice(n, size=m, replace=False)\n",
    "B = X[L]\n",
    "C = jaccard_AB(X, B, chunk=2048).astype(np.float32)\n",
    "W = jaccard_AB(B, B, chunk=1024).astype(np.float32)\n",
    "eps = 1e-6\n",
    "evals, evecs = np.linalg.eigh(W + eps*np.eye(m, dtype=np.float32))\n",
    "Winv = (evecs / evals) @ evecs.T\n",
    "Winvsqrt = (evecs / np.sqrt(evals)) @ evecs.T\n",
    "u = C.sum(axis=0)\n",
    "v = Winv @ u\n",
    "d = C @ v\n",
    "s = (1.0 / np.sqrt(d + 1e-12)).astype(np.float32)\n",
    "E = (C * s[:, None]) @ Winvsqrt\n",
    "U, S, VT = randomized_svd(E, n_components=3, random_state=0)\n",
    "Y = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "km = KMeans(n_clusters=3, n_init=10, random_state=0)\n",
    "labels = km.fit_predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1385a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaff_keys = list(scaff_to_idx.keys())\n",
    "scaff_label = {k: labels[i] for i, k in enumerate(scaff_keys)}\n",
    "\n",
    "prot_counts = {}\n",
    "sizes_total = {}\n",
    "sizes_by_ds = {}\n",
    "for k, idx in scaff_to_idx.items():\n",
    "    sub = dfu.iloc[idx]\n",
    "    prot_counts[k] = sub[prot_cols].notna().sum().to_dict()\n",
    "    sizes_total[k] = len(idx)\n",
    "    sizes_by_ds[k] = sub['__ds__'].value_counts().to_dict()\n",
    "\n",
    "total_per_prot = pd.DataFrame.from_dict(prot_counts, orient='index')[prot_cols].fillna(0).sum(axis=0).astype(int)\n",
    "need_cover = set([p for p in prot_cols if total_per_prot[p] >= 3])\n",
    "\n",
    "order = sorted(scaff_to_idx.keys(), key=lambda k: ((min([total_per_prot[p] for p,c in prot_counts[k].items() if c>0]) if any(c>0 for c in prot_counts[k].values()) else 10**9), scaff_label[k], -sizes_total[k]))\n",
    "\n",
    "ratios = np.array([0.8,0.1,0.1])\n",
    "mol_counts_ds = dfu.groupby('__ds__').size().to_dict()\n",
    "targets_ds = {ds: (ratios * mol_counts_ds[ds]).astype(int) for ds in mol_counts_ds}\n",
    "for ds in targets_ds: targets_ds[ds][0] = mol_counts_ds[ds] - targets_ds[ds][1] - targets_ds[ds][2]\n",
    "\n",
    "split_sizes_ds = {ds: np.zeros(3, dtype=int) for ds in mol_counts_ds}\n",
    "cov = {p: np.zeros(3, dtype=int) for p in prot_cols}\n",
    "assign = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1b6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_for(k, s):\n",
    "    pen = 0.0\n",
    "    for ds in split_sizes_ds:\n",
    "        sz = sizes_by_ds[k].get(ds,0)\n",
    "        if sz:\n",
    "            cur = split_sizes_ds[ds][s]\n",
    "            tgt = targets_ds[ds][s]\n",
    "            pen += (cur + sz - tgt)**2 - (cur - tgt)**2\n",
    "    for p, c in prot_counts[k].items():\n",
    "        if c>0:\n",
    "            pen += 0.01 * c * cov[p][s]\n",
    "    return pen\n",
    "\n",
    "for k in order:\n",
    "    best_s, best_pen = None, None\n",
    "    for sidx in range(3):\n",
    "        pen = penalty_for(k, sidx)\n",
    "        if best_pen is None or pen < best_pen:\n",
    "            best_pen, best_s = pen, sidx\n",
    "    assign[k] = best_s\n",
    "    for ds in split_sizes_ds:\n",
    "        split_sizes_ds[ds][best_s] += sizes_by_ds[k].get(ds,0)\n",
    "    for p, c in prot_counts[k].items():\n",
    "        if c>0: cov[p][best_s] += c\n",
    "\n",
    "mol_split = -np.ones(len(dfu), dtype=int)\n",
    "for k, s in assign.items():\n",
    "    idx = scaff_to_idx[k]\n",
    "    mol_split[idx] = s\n",
    "\n",
    "sel = pd.DataFrame({\"smiles\": dfu['smiles'].values, \"split\": mol_split, \"scaffold\": [scaf_vocab[i] if i >= 0 else None for i in scaf_id]})\n",
    "sel = sel[sel['split']>=0]\n",
    "\n",
    "for ds_name in ['chembl_pretraining','pkis2_finetuning']:\n",
    "    dfull = dfu[dfu['__ds__']==ds_name].drop(columns=['__ds__','scaffold_smiles','scaf_id'])\n",
    "    out = dfull.merge(sel[['smiles','split']], on='smiles', how='inner', validate='many_to_one')\n",
    "    for v, nm in enumerate(['train','val','test']):\n",
    "        out[out['split']==v].drop(columns=['split']).to_csv(f'datasets/{ds_name}_{nm}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
