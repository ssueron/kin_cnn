#!/usr/bin/env python3
"""
Script principal pour lancer l'entra√Ænement final optimis√© du mod√®le MultiKinaseCNN.
Combine toutes les optimisations et permet de choisir entre diff√©rentes configurations.
"""

import os
import sys
import argparse
from datetime import datetime
import json

# Configuration des variables d'environnement
os.environ['KERAS_BACKEND'] = 'torch'

# Imports des modules d'entra√Ænement
from optimized_kinase_training import AdvancedKinaseTrainer
from memory_optimized_training import MemoryOptimizedTrainer
from advanced_evaluation import AdvancedKinaseEvaluator


def setup_training_environment():
    """Configure l'environnement d'entra√Ænement."""
    print("üîß Configuration de l'environnement d'entra√Ænement...")
    
    # D√©tection GPU
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   GPU d√©tect√©: {gpu_name} ({gpu_memory:.1f} GB)")
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'
        else:
            print("   Utilisation du CPU")
            os.environ['CUDA_VISIBLE_DEVICES'] = ''
    except ImportError:
        print("   PyTorch non disponible, utilisation du CPU")
        os.environ['CUDA_VISIBLE_DEVICES'] = ''
    
    # V√©rification des fichiers de donn√©es
    required_files = [
        "processed_data/train_data.csv",
        "processed_data/train_mask.csv", 
        "processed_data/val_data.csv",
        "processed_data/val_mask.csv",
        "processed_data/test_data.csv",
        "processed_data/test_mask.csv",
        "data/smiles_vocab_extended.json"
    ]
    
    missing_files = [f for f in required_files if not os.path.exists(f)]
    if missing_files:
        print(f"‚ùå Fichiers manquants: {missing_files}")
        return False
    
    print("‚úÖ Tous les fichiers requis sont pr√©sents")
    return True


def choose_training_mode():
    """Permet de choisir le mode d'entra√Ænement."""
    print("\nüéØ CHOIX DU MODE D'ENTRA√éNEMENT")
    print("=" * 50)
    print("1. üöÄ Mode Performance  - Entra√Ænement optimis√© avec toutes les fonctionnalit√©s")
    print("2. üíæ Mode M√©moire     - Entra√Ænement optimis√© pour syst√®mes √† m√©moire limit√©e")
    print("3. ‚ö° Mode Rapide      - Entra√Ænement rapide pour tests (param√®tres r√©duits)")
    print("4. üî¨ Mode Recherche   - Grid search automatique des hyperparam√®tres")
    
    while True:
        try:
            choice = int(input("\nVotre choix (1-4): "))
            if 1 <= choice <= 4:
                return choice
            else:
                print("‚ùå Choix invalide. Entrez un nombre entre 1 et 4.")
        except ValueError:
            print("‚ùå Entr√©e invalide. Entrez un nombre.")


def get_training_parameters(mode):
    """Retourne les param√®tres d'entra√Ænement selon le mode choisi."""
    configs = {
        1: {  # Mode Performance
            'name': 'Performance',
            'epochs': 200,
            'learning_rate': 1e-3,
            'batch_size': 64,
            'patience': 25,
            'model_size': 'large'
        },
        2: {  # Mode M√©moire  
            'name': 'M√©moire',
            'epochs': 150,
            'learning_rate': 1e-3,
            'batch_size': 32,
            'patience': 20,
            'model_size': 'medium'
        },
        3: {  # Mode Rapide
            'name': 'Rapide',
            'epochs': 50,
            'learning_rate': 2e-3,
            'batch_size': 128,
            'patience': 10,
            'model_size': 'small'
        },
        4: {  # Mode Recherche
            'name': 'Recherche',
            'epochs': 100,
            'learning_rate': 'auto',
            'batch_size': 'auto',
            'patience': 15,
            'model_size': 'auto'
        }
    }
    
    return configs[mode]


def run_performance_mode(config):
    """Lance l'entra√Ænement en mode performance."""
    print(f"\nüöÄ LANCEMENT EN MODE {config['name'].upper()}")
    print("=" * 60)
    
    # Utiliser le trainer avanc√©
    trainer = AdvancedKinaseTrainer()
    
    # Adapter la configuration
    trainer.optimized_params['training']['epochs'] = config['epochs']
    trainer.optimized_params['training']['learning_rate'] = config['learning_rate']
    trainer.optimized_params['training']['batch_size'] = config['batch_size']
    trainer.optimized_params['training']['patience'] = config['patience']
    
    # Lancer l'entra√Ænement
    model, history, model_path = trainer.run_complete_training()
    
    return model, history, model_path, trainer.optimized_params


def run_memory_mode(config):
    """Lance l'entra√Ænement en mode m√©moire optimis√©e."""
    print(f"\nüíæ LANCEMENT EN MODE {config['name'].upper()}")
    print("=" * 60)
    
    # Utiliser le trainer optimis√© m√©moire
    trainer = MemoryOptimizedTrainer()
    
    # Adapter la configuration
    trainer.memory_config['batch_size'] = config['batch_size']
    
    # Lancer l'entra√Ænement
    model, history, model_path = trainer.run_optimized_training(
        epochs=config['epochs'],
        learning_rate=config['learning_rate']
    )
    
    return model, history, model_path, trainer.model_config


def run_fast_mode(config):
    """Lance l'entra√Ænement en mode rapide."""
    print(f"\n‚ö° LANCEMENT EN MODE {config['name'].upper()}")
    print("=" * 60)
    
    # Utiliser le trainer avanc√© avec param√®tres r√©duits
    trainer = AdvancedKinaseTrainer()
    
    # Configuration all√©g√©e pour mode rapide
    trainer.optimized_params['model']['embedding_dim'] = 64
    trainer.optimized_params['model']['n_layers'] = 2
    trainer.optimized_params['model']['n_filters'] = 32
    trainer.optimized_params['model']['dense_layer_size'] = 256
    
    trainer.optimized_params['training']['epochs'] = config['epochs']
    trainer.optimized_params['training']['learning_rate'] = config['learning_rate']
    trainer.optimized_params['training']['batch_size'] = config['batch_size']
    trainer.optimized_params['training']['patience'] = config['patience']
    
    # Lancer l'entra√Ænement
    model, history, model_path = trainer.run_complete_training()
    
    return model, history, model_path, trainer.optimized_params


def run_research_mode(config):
    """Lance la recherche automatique d'hyperparam√®tres."""
    print(f"\nüî¨ LANCEMENT EN MODE {config['name'].upper()}")
    print("=" * 60)
    print("üîç Grid search des hyperparam√®tres...")
    
    # D√©finir la grille de recherche
    param_grid = {
        'learning_rate': [1e-4, 5e-4, 1e-3, 2e-3],
        'batch_size': [32, 64, 128],
        'dropout': [0.3, 0.4, 0.5],
        'embedding_dim': [96, 128, 160],
        'n_filters': [48, 64, 80]
    }
    
    best_score = float('inf')
    best_config = None
    best_model_path = None
    
    total_combinations = 1
    for values in param_grid.values():
        total_combinations *= len(values)
    
    print(f"üéØ {total_combinations} combinaisons √† tester...")
    
    combination = 0
    for lr in param_grid['learning_rate']:
        for bs in param_grid['batch_size']:
            for dropout in param_grid['dropout']:
                for emb_dim in param_grid['embedding_dim']:
                    for n_filters in param_grid['n_filters']:
                        combination += 1
                        print(f"\nüß™ Test {combination}/{total_combinations}: LR={lr}, BS={bs}, Dropout={dropout}, Emb={emb_dim}, Filters={n_filters}")
                        
                        # Cr√©er trainer avec cette config
                        trainer = AdvancedKinaseTrainer()
                        
                        # Appliquer les param√®tres
                        trainer.optimized_params['training']['learning_rate'] = lr
                        trainer.optimized_params['training']['batch_size'] = bs
                        trainer.optimized_params['training']['epochs'] = config['epochs']
                        trainer.optimized_params['training']['patience'] = config['patience']
                        trainer.optimized_params['model']['dropout'] = dropout
                        trainer.optimized_params['model']['embedding_dim'] = emb_dim
                        trainer.optimized_params['model']['n_filters'] = n_filters
                        
                        try:
                            # Entra√Ænement
                            model, history, model_path = trainer.run_complete_training()
                            
                            # √âvaluer la performance
                            final_val_loss = history['val_loss'][-1]
                            
                            if final_val_loss < best_score:
                                best_score = final_val_loss
                                best_config = {
                                    'learning_rate': lr,
                                    'batch_size': bs, 
                                    'dropout': dropout,
                                    'embedding_dim': emb_dim,
                                    'n_filters': n_filters
                                }
                                best_model_path = model_path
                                
                                print(f"‚úÖ Nouveau meilleur score: {best_score:.6f}")
                            else:
                                print(f"üìä Score: {final_val_loss:.6f} (meilleur: {best_score:.6f})")
                                
                        except Exception as e:
                            print(f"‚ùå Erreur lors de l'entra√Ænement: {e}")
                            continue
    
    print(f"\nüèÜ MEILLEURE CONFIGURATION TROUV√âE:")
    print(f"   Score (val_loss): {best_score:.6f}")
    print(f"   Param√®tres: {best_config}")
    print(f"   Mod√®le: {best_model_path}")
    
    return None, None, best_model_path, best_config


def run_evaluation(model_path, results_path=None):
    """Lance l'√©valuation du mod√®le entra√Æn√©."""
    print(f"\nüìä √âVALUATION DU MOD√àLE")
    print("=" * 50)
    
    if not os.path.exists(model_path):
        print(f"‚ùå Mod√®le non trouv√©: {model_path}")
        return None, None
    
    try:
        evaluator = AdvancedKinaseEvaluator(model_path, results_path)
        kinase_metrics, overall_metrics = evaluator.run_complete_evaluation()
        return kinase_metrics, overall_metrics
    except Exception as e:
        print(f"‚ùå Erreur lors de l'√©valuation: {e}")
        return None, None


def save_session_summary(mode_config, model_path, training_params, evaluation_results=None):
    """Sauvegarde un r√©sum√© complet de la session d'entra√Ænement."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    summary = {
        'session_timestamp': timestamp,
        'training_mode': mode_config['name'],
        'training_config': mode_config,
        'model_path': model_path,
        'training_parameters': training_params,
        'evaluation_results': evaluation_results,
        'system_info': {
            'python_version': sys.version,
            'has_cuda': os.environ.get('CUDA_VISIBLE_DEVICES', '') != ''
        }
    }
    
    summary_path = f"training_session_summary_{timestamp}.json"
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2, default=str)
    
    print(f"üìã R√©sum√© de session sauvegard√©: {summary_path}")
    return summary_path


def main():
    """Point d'entr√©e principal."""
    print("üß¨ ENTRA√éNEMENT FINAL MULTIKINASECNN")
    print("=" * 60)
    print("üéØ Pr√©diction d'activit√© biomol√©culaire multi-kinases")
    print("üìä Dataset: 79,492 mol√©cules √ó 357 kinases (sparsit√© 0.43%)")
    print("=" * 60)
    
    # Configuration de l'environnement
    if not setup_training_environment():
        print("‚ùå √âchec de la configuration. Arr√™t.")
        return
    
    # Choix du mode d'entra√Ænement
    mode = choose_training_mode()
    config = get_training_parameters(mode)
    
    print(f"\nüìã Configuration s√©lectionn√©e: {config}")
    input("\nAppuyez sur Entr√©e pour continuer...")
    
    # Lancement de l'entra√Ænement selon le mode
    model = None
    history = None
    model_path = None
    training_params = None
    
    try:
        if mode == 1:  # Performance
            model, history, model_path, training_params = run_performance_mode(config)
        elif mode == 2:  # M√©moire
            model, history, model_path, training_params = run_memory_mode(config)
        elif mode == 3:  # Rapide
            model, history, model_path, training_params = run_fast_mode(config)
        elif mode == 4:  # Recherche
            model, history, model_path, training_params = run_research_mode(config)
        
        if model_path is None:
            print("‚ùå √âchec de l'entra√Ænement")
            return
            
        print(f"\n‚úÖ ENTRA√éNEMENT R√âUSSI!")
        print(f"üìÅ Mod√®le sauvegard√©: {model_path}")
        
        # √âvaluation automatique
        print("\nü§î Lancer l'√©valuation du mod√®le? (y/n): ", end="")
        if input().lower() == 'y':
            # Trouver le fichier de r√©sultats correspondant
            results_path = model_path.replace('.weights.h5', '').replace('model', 'results') + '.json'
            if not os.path.exists(results_path):
                results_path = None
                
            evaluation_results = run_evaluation(model_path, results_path)
        else:
            evaluation_results = None
        
        # Sauvegarder le r√©sum√© de session
        summary_path = save_session_summary(config, model_path, training_params, evaluation_results)
        
        print(f"\nüéâ SESSION TERMIN√âE AVEC SUCC√àS!")
        print(f"üìÅ Fichiers g√©n√©r√©s:")
        print(f"   Mod√®le: {model_path}")
        print(f"   R√©sum√©: {summary_path}")
        
        if evaluation_results:
            print(f"üìä Performance globale: R¬≤ = {evaluation_results[1]['r2']:.4f}")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Entra√Ænement interrompu par l'utilisateur")
    except Exception as e:
        print(f"\n‚ùå Erreur lors de l'entra√Ænement: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()