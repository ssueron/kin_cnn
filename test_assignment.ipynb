{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d45b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter-ready splitter (pretraining + finetuning, scaffold-based, family-stratified)\n",
    "\n",
    "import os, hashlib, json\n",
    "import numpy as np, pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold as MS\n",
    "\n",
    "def canon_smiles(s):\n",
    "    m = Chem.MolFromSmiles(str(s))\n",
    "    return None if m is None else Chem.MolToSmiles(m, canonical=True)\n",
    "def inchikey(s):\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    return None if m is None else Chem.MolToInchiKey(m)\n",
    "def scaffold_smiles(s):\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    if m is None: return None\n",
    "    scaf = MS.GetScaffoldForMol(m)\n",
    "    return Chem.MolToSmiles(scaf, canonical=True) if scaf is not None else None\n",
    "def det_order(keys, seed):\n",
    "    def h(x): return int(hashlib.md5((str(seed)+x).encode()).hexdigest(),16)\n",
    "    return sorted(keys, key=h)\n",
    "def load_map(path, protein_col, family_col):\n",
    "    mp = pd.read_csv(path)\n",
    "    mp = mp[[protein_col, family_col]].dropna()\n",
    "    mp[protein_col] = mp[protein_col].astype(str)\n",
    "    mp[family_col] = mp[family_col].astype(str)\n",
    "    return dict(zip(mp[protein_col], mp[family_col]))\n",
    "def prep_df(path, smiles_col, protein2fam):\n",
    "    df = pd.read_csv(path)\n",
    "    df['__smiles'] = df[smiles_col].map(canon_smiles)\n",
    "    df = df.dropna(subset=['__smiles']).drop_duplicates('__smiles').reset_index(drop=True)\n",
    "    df['__inchikey'] = df['__smiles'].map(inchikey)\n",
    "    pcols = [c for c in df.columns if c in protein2fam]\n",
    "    fams = sorted(set(protein2fam[c] for c in pcols))\n",
    "    fam2idx = {f:i for i,f in enumerate(fams)}\n",
    "    M = np.zeros((len(df), len(fams)), dtype=int)\n",
    "    for f in fams:\n",
    "        cols = [c for c in pcols if protein2fam[c]==f]\n",
    "        if cols:\n",
    "            M[:, fam2idx[f]] = (df[cols].fillna(0).astype(float).values>0).any(axis=1).astype(int)\n",
    "    df['__scaffold'] = df['__smiles'].map(scaffold_smiles)\n",
    "    df = df.dropna(subset=['__scaffold']).reset_index(drop=True)\n",
    "    return df, fams, M\n",
    "def aggregate_scaffolds(df, fams, M):\n",
    "    rows = []\n",
    "    for scaf, idxs in df.groupby('__scaffold').indices.items():\n",
    "        ids = list(idxs)\n",
    "        vec = M[ids].sum(axis=0)\n",
    "        dom = fams[int(vec.argmax())] if vec.sum()>0 else None\n",
    "        rows.append({'scaffold':scaf,'n':len(ids),'smiles_set':set(df.loc[ids,'__smiles']), 'fam_vec':vec, 'dominant_family':dom})\n",
    "    return pd.DataFrame(rows)\n",
    "def greedy_split(scaf_df, fams, ratios, seed, forbid_train_scaffolds=set(), forbid_train_smiles=set()):\n",
    "    total = scaf_df['n'].sum()\n",
    "    F = len(fams)\n",
    "    fam_tot = np.zeros(F, dtype=float)\n",
    "    for v in scaf_df['fam_vec']: fam_tot += v\n",
    "    tgt_size = {k:int(round(total*r)) for k,r in ratios.items()}\n",
    "    tgt_fam = {k:(fam_tot*r) for k,r in ratios.items()}\n",
    "    cur_size = {k:0 for k in ratios}\n",
    "    cur_fam = {k:np.zeros(F, dtype=float) for k in ratios}\n",
    "    assign = {}\n",
    "    order = det_order(list(scaf_df['scaffold']), seed)\n",
    "    pos = {s:i for i,s in enumerate(scaf_df['scaffold'])}\n",
    "    for s in order:\n",
    "        row = scaf_df.iloc[pos[s]]\n",
    "        gains = {}\n",
    "        for split in ratios:\n",
    "            if split=='train' and (s in forbid_train_scaffolds or (row['smiles_set'] & forbid_train_smiles)):\n",
    "                gains[split] = -1e18\n",
    "                continue\n",
    "            fam_need = np.maximum(tgt_fam[split]-cur_fam[split], 0)\n",
    "            size_need = max(tgt_size[split]-cur_size[split], 0)\n",
    "            gains[split] = float(np.minimum(row['fam_vec'], fam_need).sum()) + min(row['n'], size_need)*0.1\n",
    "        best = max(gains, key=lambda k:(gains[k], -cur_size[k]))\n",
    "        assign[s] = best\n",
    "        cur_size[best] += row['n']\n",
    "        cur_fam[best] += row['fam_vec']\n",
    "    scaf_df['split'] = scaf_df['scaffold'].map(assign)\n",
    "    return scaf_df\n",
    "def finalize_compounds(df, scaf_assign):\n",
    "    m = dict(zip(scaf_assign['scaffold'], scaf_assign['split']))\n",
    "    df['split'] = df['__scaffold'].map(m)\n",
    "    return df\n",
    "def family_summary(df, fams, M):\n",
    "    out = []\n",
    "    for sp in ['train','val','test']:\n",
    "        mask = (df['split']==sp).values\n",
    "        vec = np.zeros(len(fams),dtype=int) if mask.sum()==0 else M[mask].sum(axis=0)\n",
    "        out.append(pd.DataFrame({'family':fams,'split':sp,'active_compounds':vec}))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "def align(df, fams_all, fams_local, M_local):\n",
    "    idx = {f:i for i,f in enumerate(fams_local)}\n",
    "    M = np.zeros((len(df), len(fams_all)), dtype=int)\n",
    "    for j,f in enumerate(fams_all):\n",
    "        if f in idx: M[:,j] = M_local[:, idx[f]]\n",
    "    return M\n",
    "\n",
    "# ---- Configure paths/params (edit these) ----\n",
    "pretraining_path = 'datasets/chembl_pretraining.csv'\n",
    "finetuning_path = 'datasets/pkis2_finetuning.csv'\n",
    "mapping_path = 'uniprotkb_chembl_ID_kinomescan_cleaned.csv'\n",
    "smiles_col = 'smiles'\n",
    "protein_col = 'KINOMEscanÂ® Gene Symbol'\n",
    "family_col = 'Family'\n",
    "ratios = {'train':0.8,'val':0.1,'test':0.1}\n",
    "seed = 42\n",
    "outdir = 'splits_out'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ---- Run ----\n",
    "protein2fam = load_map(mapping_path, protein_col, family_col)\n",
    "df_fine, fams_f, M_f_local = prep_df(finetuning_path, smiles_col, protein2fam)\n",
    "df_pre,  fams_p, M_p_local = prep_df(pretraining_path, smiles_col, protein2fam)\n",
    "fams = sorted(set(fams_f) | set(fams_p))\n",
    "M_f = align(df_fine, fams, fams_f, M_f_local)\n",
    "M_p = align(df_pre,  fams, fams_p, M_p_local)\n",
    "\n",
    "scaf_f = aggregate_scaffolds(df_fine, fams, M_f)\n",
    "scaf_f = greedy_split(scaf_f, fams, ratios, seed)\n",
    "df_fine = finalize_compounds(df_fine, scaf_f)\n",
    "\n",
    "forbid_scafs = set(scaf_f.loc[scaf_f['split'].isin(['val','test']),'scaffold'])\n",
    "lst = scaf_f.loc[scaf_f['split'].isin(['val','test']),'smiles_set'].tolist()\n",
    "forbid_smiles = set().union(*lst) if len(lst)>0 else set()\n",
    "\n",
    "scaf_p = aggregate_scaffolds(df_pre, fams, M_p)\n",
    "scaf_p = greedy_split(scaf_p, fams, ratios, seed+1, forbid_scafs, forbid_smiles)\n",
    "df_pre = finalize_compounds(df_pre, scaf_p)\n",
    "\n",
    "df_fine.to_csv(os.path.join(outdir,'finetuning_with_splits.csv'), index=False)\n",
    "df_pre.to_csv(os.path.join(outdir,'pretraining_with_splits.csv'), index=False)\n",
    "for dname, df in [('finetuning', df_fine), ('pretraining', df_pre)]:\n",
    "    for sp in ['train','val','test']:\n",
    "        df[df['split']==sp].to_csv(os.path.join(outdir,f'{dname}_{sp}.csv'), index=False)\n",
    "\n",
    "sa = pd.concat([\n",
    "    scaf_f.assign(dataset='finetuning')[['scaffold','split','n','dominant_family']],\n",
    "    scaf_p.assign(dataset='pretraining')[['scaffold','split','n','dominant_family']]\n",
    "])\n",
    "sa.to_csv(os.path.join(outdir,'scaffold_assignments.csv'), index=False)\n",
    "fs_f = family_summary(df_fine, fams, M_f).assign(dataset='finetuning')\n",
    "fs_p = family_summary(df_pre, fams, M_p).assign(dataset='pretraining')\n",
    "pd.concat([fs_f, fs_p]).to_csv(os.path.join(outdir,'family_coverage_summary.csv'), index=False)\n",
    "overlap = pd.DataFrame({'scaffold':list(set(scaf_f['scaffold']) & set(scaf_p['scaffold']))})\n",
    "overlap = overlap.merge(scaf_f[['scaffold','split']].rename(columns={'split':'finetuning_split'}), on='scaffold', how='left')\n",
    "overlap = overlap.merge(scaf_p[['scaffold','split']].rename(columns={'split':'pretraining_split'}), on='scaffold', how='left')\n",
    "overlap.to_csv(os.path.join(outdir,'overlap_report.csv'), index=False)\n",
    "\n",
    "assert len(set(df_fine.groupby('__scaffold')['split'].nunique()))==1\n",
    "assert len(set(df_pre.groupby('__scaffold')['split'].nunique()))==1\n",
    "assert not bool(forbid_scafs & set(scaf_p.loc[scaf_p['split']=='train','scaffold']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
