{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d70e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hierarchical Butina clustering with threshold 0.6 using 12 workers...\n",
      "Loaded 79,492 SMILES\n",
      "Computing fingerprints...\n",
      "Generated 79,492 valid fingerprints (dropped 0 invalid) in 4.0s\n",
      "Performing hierarchical Butina clustering...\n",
      "Starting hierarchical Butina clustering (threshold=0.6)\n",
      "Dataset size: 79,492 molecules\n",
      "Creating diverse subsample of 15,000 from 79,492 molecules...\n",
      "  Selected 1,000/15,000 diverse molecules...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 308\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Run the clustering\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m cluster_molecules(\n\u001b[1;32m    309\u001b[0m         csv_file\u001b[38;5;241m=\u001b[39mCSV_FILE,\n\u001b[1;32m    310\u001b[0m         smiles_col\u001b[38;5;241m=\u001b[39mSMILES_COL, \n\u001b[1;32m    311\u001b[0m         thresh\u001b[38;5;241m=\u001b[39mTHRESHOLD,\n\u001b[1;32m    312\u001b[0m         workers\u001b[38;5;241m=\u001b[39mWORKERS,\n\u001b[1;32m    313\u001b[0m         out_csv\u001b[38;5;241m=\u001b[39mOUTPUT_FILE\n\u001b[1;32m    314\u001b[0m     )\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClustering completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 271\u001b[0m, in \u001b[0;36mcluster_molecules\u001b[0;34m(csv_file, smiles_col, thresh, workers, out_csv)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming hierarchical Butina clustering...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(fps)))\n\u001b[0;32m--> 271\u001b[0m cluster_assignments \u001b[38;5;241m=\u001b[39m hierarchical_butina_clustering(fps, indices, thresh)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# 4  Create results dataframe and save\u001b[39;00m\n\u001b[1;32m    274\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m i: cluster_assignments\u001b[38;5;241m.\u001b[39mget(i, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m, in \u001b[0;36mhierarchical_butina_clustering\u001b[0;34m(fps, indices, thresh, max_subsample, progress_interval)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m direct_butina_clustering(fps, indices, thresh)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Stage 1: Create diverse subsample\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m subsample_fps, subsample_indices \u001b[38;5;241m=\u001b[39m diverse_subsample(fps, indices, max_subsample)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Stage 2: Apply Butina to subsample\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying Butina clustering to subsample of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(subsample_fps)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m molecules...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36mdiverse_subsample\u001b[0;34m(fps, indices, target_size, random_seed)\u001b[0m\n\u001b[1;32m     69\u001b[0m check_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(remaining_indices, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(remaining_indices)))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m check_indices:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Find minimum distance to any selected molecule\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     min_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m DataStructs\u001b[38;5;241m.\u001b[39mTanimotoSimilarity(fps[idx], sel_fp) \n\u001b[1;32m     74\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m sel_fp \u001b[38;5;129;01min\u001b[39;00m selected_fps)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m min_dist \u001b[38;5;241m>\u001b[39m max_min_dist:\n\u001b[1;32m     77\u001b[0m         max_min_dist \u001b[38;5;241m=\u001b[39m min_dist\n",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m check_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(remaining_indices, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(remaining_indices)))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m check_indices:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Find minimum distance to any selected molecule\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     min_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m DataStructs\u001b[38;5;241m.\u001b[39mTanimotoSimilarity(fps[idx], sel_fp) \n\u001b[1;32m     74\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m sel_fp \u001b[38;5;129;01min\u001b[39;00m selected_fps)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m min_dist \u001b[38;5;241m>\u001b[39m max_min_dist:\n\u001b[1;32m     77\u001b[0m         max_min_dist \u001b[38;5;241m=\u001b[39m min_dist\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv, os, multiprocessing as mp\n",
    "import time\n",
    "import random\n",
    "from functools import partial\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from rdkit.ML.Cluster import Butina\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- helpers ----------------------------------------------------------\n",
    "\n",
    "def mol_from_smiles(sm):\n",
    "    \"\"\"SMILES → Mol (silently skips invalid)\"\"\"\n",
    "    m = Chem.MolFromSmiles(sm)\n",
    "    return m\n",
    "\n",
    "# Create Morgan fingerprint generator (modern approach)\n",
    "morgan_generator = GetMorganGenerator(radius=3, fpSize=2048)\n",
    "\n",
    "def ecfp6(mol):\n",
    "    \"\"\"RDKit ECFP6 using modern MorganGenerator\"\"\"\n",
    "    return morgan_generator.GetFingerprint(mol) if mol else None\n",
    "\n",
    "def fp_chunk(smiles):\n",
    "    \"\"\"worker: SMILES → fingerprint (or None)\"\"\"\n",
    "    mol = mol_from_smiles(smiles)\n",
    "    return ecfp6(mol)\n",
    "\n",
    "def build_dist_mat(fps, thresh=0.6):\n",
    "    \"\"\"\n",
    "    Upper-triangular distance list for Butina:\n",
    "      dist = 1 - tanimoto\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    for i in range(1, len(fps)):\n",
    "        sims = DataStructs.BulkTanimotoSimilarity(fps[i], fps[:i])\n",
    "        dists.extend(1 - s for s in sims)\n",
    "    return dists\n",
    "\n",
    "def diverse_subsample(fps, indices, target_size=15000, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create diverse subsample using MaxMin algorithm\n",
    "    Returns: (subsample_fps, subsample_indices)\n",
    "    \"\"\"\n",
    "    if len(fps) <= target_size:\n",
    "        return fps, indices\n",
    "    \n",
    "    print(f\"Creating diverse subsample of {target_size:,} from {len(fps):,} molecules...\")\n",
    "    \n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Start with random molecule\n",
    "    selected_indices = [random.randint(0, len(fps) - 1)]\n",
    "    selected_fps = [fps[selected_indices[0]]]\n",
    "    remaining_indices = list(range(len(fps)))\n",
    "    remaining_indices.remove(selected_indices[0])\n",
    "    \n",
    "    # MaxMin selection: pick molecule most distant from already selected\n",
    "    for i in range(1, min(target_size, len(fps))):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"  Selected {i:,}/{target_size:,} diverse molecules...\")\n",
    "        \n",
    "        max_min_dist = -1\n",
    "        best_idx = -1\n",
    "        \n",
    "        # Sample subset for efficiency (check 1000 random molecules)\n",
    "        check_indices = random.sample(remaining_indices, min(1000, len(remaining_indices)))\n",
    "        \n",
    "        for idx in check_indices:\n",
    "            # Find minimum distance to any selected molecule\n",
    "            min_dist = min(1 - DataStructs.TanimotoSimilarity(fps[idx], sel_fp) \n",
    "                          for sel_fp in selected_fps)\n",
    "            \n",
    "            if min_dist > max_min_dist:\n",
    "                max_min_dist = min_dist\n",
    "                best_idx = idx\n",
    "        \n",
    "        selected_indices.append(best_idx)\n",
    "        selected_fps.append(fps[best_idx])\n",
    "        remaining_indices.remove(best_idx)\n",
    "    \n",
    "    # Map back to original indices\n",
    "    original_indices = [indices[i] for i in selected_indices]\n",
    "    \n",
    "    print(f\"  Diverse subsample created: {len(selected_fps):,} molecules\")\n",
    "    return selected_fps, original_indices\n",
    "\n",
    "def hierarchical_butina_clustering(fps, indices, thresh=0.6, max_subsample=15000, progress_interval=2000):\n",
    "    \"\"\"\n",
    "    Hierarchical Butina clustering for large datasets\n",
    "    \n",
    "    Stage 1: Create diverse subsample\n",
    "    Stage 2: Apply Butina clustering to subsample  \n",
    "    Stage 3: Assign remaining molecules to nearest cluster centroids\n",
    "    \n",
    "    Parameters:\n",
    "    - fps: list of fingerprints\n",
    "    - indices: original indices of molecules\n",
    "    - thresh: similarity threshold\n",
    "    - max_subsample: maximum size for Butina clustering\n",
    "    - progress_interval: progress reporting interval\n",
    "    \n",
    "    Returns:\n",
    "    - cluster_assignments: dict mapping original_index -> cluster_id\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Starting hierarchical Butina clustering (threshold={thresh})\")\n",
    "    print(f\"Dataset size: {len(fps):,} molecules\")\n",
    "    \n",
    "    if len(fps) <= max_subsample:\n",
    "        print(\"Dataset small enough for direct Butina clustering\")\n",
    "        return direct_butina_clustering(fps, indices, thresh)\n",
    "    \n",
    "    # Stage 1: Create diverse subsample\n",
    "    subsample_fps, subsample_indices = diverse_subsample(fps, indices, max_subsample)\n",
    "    \n",
    "    # Stage 2: Apply Butina to subsample\n",
    "    print(f\"Applying Butina clustering to subsample of {len(subsample_fps):,} molecules...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    dists = build_dist_mat(subsample_fps, thresh)\n",
    "    print(f\"Built distance matrix ({len(dists):,} distances) in {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "    clusters = Butina.ClusterData(\n",
    "        dists, len(subsample_fps), distThresh=1 - thresh, isDistData=True\n",
    "    )\n",
    "    butina_time = time.time() - start_time\n",
    "    print(f\"Butina clustering completed in {butina_time:.1f}s: {len(clusters):,} clusters\")\n",
    "    \n",
    "    # Create cluster centroids from subsample\n",
    "    cluster_centroids = {}\n",
    "    subsample_assignments = {}\n",
    "    \n",
    "    for cluster_id, cluster in enumerate(clusters):\n",
    "        centroid_idx = cluster[0]  # First molecule in cluster is centroid\n",
    "        cluster_centroids[cluster_id] = subsample_fps[centroid_idx]\n",
    "        \n",
    "        # Assign all molecules in this cluster\n",
    "        for mol_idx in cluster:\n",
    "            original_idx = subsample_indices[mol_idx]\n",
    "            subsample_assignments[original_idx] = cluster_id\n",
    "    \n",
    "    print(f\"Created {len(cluster_centroids):,} cluster centroids\")\n",
    "    \n",
    "    # Stage 3: Assign remaining molecules to nearest centroids\n",
    "    print(\"Assigning remaining molecules to clusters...\")\n",
    "    \n",
    "    # Create set of subsampled indices for fast lookup\n",
    "    subsampled_set = set(subsample_indices)\n",
    "    \n",
    "    cluster_assignments = subsample_assignments.copy()\n",
    "    assignment_start = time.time()\n",
    "    processed = 0\n",
    "    \n",
    "    for i, (fp, orig_idx) in enumerate(zip(fps, indices)):\n",
    "        if fp is None:\n",
    "            cluster_assignments[orig_idx] = -1  # Invalid molecule\n",
    "            continue\n",
    "            \n",
    "        if orig_idx in subsampled_set:\n",
    "            continue  # Already assigned in subsample\n",
    "        \n",
    "        # Find nearest cluster centroid\n",
    "        best_cluster = None\n",
    "        best_sim = 0\n",
    "        \n",
    "        for cluster_id, centroid_fp in cluster_centroids.items():\n",
    "            sim = DataStructs.TanimotoSimilarity(fp, centroid_fp)\n",
    "            if sim >= thresh and sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_cluster = cluster_id\n",
    "        \n",
    "        if best_cluster is not None:\n",
    "            cluster_assignments[orig_idx] = best_cluster\n",
    "        else:\n",
    "            # Create new singleton cluster\n",
    "            new_cluster_id = len(cluster_centroids)\n",
    "            cluster_centroids[new_cluster_id] = fp\n",
    "            cluster_assignments[orig_idx] = new_cluster_id\n",
    "        \n",
    "        processed += 1\n",
    "        \n",
    "        # Progress reporting\n",
    "        if processed % progress_interval == 0:\n",
    "            elapsed = time.time() - assignment_start\n",
    "            remaining = len(fps) - len(subsampled_set) - processed\n",
    "            rate = processed / elapsed if elapsed > 0 else 0\n",
    "            eta = remaining / rate if rate > 0 else 0\n",
    "            \n",
    "            print(f\"  Assigned {processed:,} molecules | \"\n",
    "                  f\"Rate: {rate:.1f} mol/s | \"\n",
    "                  f\"ETA: {eta/60:.1f}min | \"\n",
    "                  f\"Total clusters: {len(cluster_centroids):,}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Hierarchical clustering completed in {total_time:.1f}s\")\n",
    "    print(f\"Final cluster count: {len(cluster_centroids):,}\")\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "def direct_butina_clustering(fps, indices, thresh=0.6):\n",
    "    \"\"\"Direct Butina clustering for smaller datasets\"\"\"\n",
    "    print(\"Applying direct Butina clustering...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dists = build_dist_mat(fps, thresh)\n",
    "    print(f\"Built distance matrix in {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "    clusters = Butina.ClusterData(\n",
    "        dists, len(fps), distThresh=1 - thresh, isDistData=True\n",
    "    )\n",
    "    print(f\"Butina clustering completed: {len(clusters):,} clusters\")\n",
    "    \n",
    "    # Map to cluster assignments\n",
    "    cluster_assignments = {}\n",
    "    for cluster_id, cluster in enumerate(clusters):\n",
    "        for mol_idx in cluster:\n",
    "            original_idx = indices[mol_idx]\n",
    "            cluster_assignments[original_idx] = cluster_id\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "# ---------- main workflow (notebook version) --------------------------------\n",
    "\n",
    "def cluster_molecules(csv_file, smiles_col=\"smiles\", thresh=0.6, workers=None, out_csv=\"clusters.csv\"):\n",
    "    \"\"\"\n",
    "    Cluster molecules using hierarchical Butina clustering\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_file: path to input CSV file\n",
    "    - smiles_col: column name containing SMILES\n",
    "    - thresh: Tanimoto similarity threshold (0.55 = 55% similarity)\n",
    "    - workers: number of parallel workers (None = use all cores - 1)\n",
    "    - out_csv: output file name\n",
    "    \"\"\"\n",
    "    \n",
    "    if workers is None:\n",
    "        workers = max(1, os.cpu_count() - 1)\n",
    "    \n",
    "    print(f\"Starting hierarchical Butina clustering with threshold {thresh} using {workers} workers...\")\n",
    "    \n",
    "    # 1  Read SMILES\n",
    "    df = pd.read_csv(csv_file)\n",
    "    smiles = df[smiles_col].tolist()\n",
    "    print(f\"Loaded {len(smiles):,} SMILES\")\n",
    "\n",
    "    # 2  Parallel fingerprints\n",
    "    print(\"Computing fingerprints...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if workers > 1:\n",
    "        try:\n",
    "            ctx = mp.get_context(\"fork\")\n",
    "            with ctx.Pool(processes=workers) as pool:\n",
    "                fps = pool.map(fp_chunk, smiles)\n",
    "        except:\n",
    "            print(\"Multiprocessing failed, using sequential processing...\")\n",
    "            fps = [fp_chunk(sm) for sm in smiles]\n",
    "    else:\n",
    "        fps = [fp_chunk(sm) for sm in smiles]\n",
    "    \n",
    "    fp_time = time.time() - start_time\n",
    "    valid_count = sum(1 for fp in fps if fp is not None)\n",
    "    print(f\"Generated {valid_count:,} valid fingerprints (dropped {len(smiles) - valid_count} invalid) in {fp_time:.1f}s\")\n",
    "\n",
    "    # 3  Hierarchical Butina clustering\n",
    "    print(\"Performing hierarchical Butina clustering...\")\n",
    "    indices = list(range(len(fps)))\n",
    "    cluster_assignments = hierarchical_butina_clustering(fps, indices, thresh)\n",
    "\n",
    "    # 4  Create results dataframe and save\n",
    "    df['cluster_id'] = df.index.map(lambda i: cluster_assignments.get(i, -1))\n",
    "    \n",
    "    # Save to CSV\n",
    "    df[[smiles_col, 'cluster_id']].to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote {out_csv}\")\n",
    "    \n",
    "    # Print cluster statistics\n",
    "    cluster_series = df['cluster_id']\n",
    "    valid_clusters = cluster_series[cluster_series >= 0]\n",
    "    cluster_sizes = valid_clusters.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"\\nCluster statistics:\")\n",
    "    print(f\"Total clusters: {len(cluster_sizes)}\")\n",
    "    print(f\"Valid molecules clustered: {len(valid_clusters):,}\")\n",
    "    print(f\"Invalid molecules: {(cluster_series == -1).sum()}\")\n",
    "    print(f\"Largest cluster: {cluster_sizes.iloc[0] if len(cluster_sizes) > 0 else 0} molecules\")\n",
    "    print(f\"Clusters with >10 molecules: {(cluster_sizes > 10).sum()}\")\n",
    "    print(f\"Clusters with >100 molecules: {(cluster_sizes > 100).sum()}\")\n",
    "    print(f\"Singleton clusters: {(cluster_sizes == 1).sum()}\")\n",
    "    print(f\"Mean cluster size: {cluster_sizes.mean():.1f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ---------- Run clustering ---------------------------------------------------\n",
    "\n",
    "# Set parameters\n",
    "CSV_FILE = \"chembl_pretraining.csv\"\n",
    "SMILES_COL = \"smiles\"\n",
    "THRESHOLD = 0.6  # 60% Tanimoto similarity threshold\n",
    "WORKERS = 12       # Adjust based on your system\n",
    "OUTPUT_FILE = \"chembl_clusters_hierarchical.csv\"\n",
    "\n",
    "# Run the clustering\n",
    "try:\n",
    "    result_df = cluster_molecules(\n",
    "        csv_file=CSV_FILE,\n",
    "        smiles_col=SMILES_COL, \n",
    "        thresh=THRESHOLD,\n",
    "        workers=WORKERS,\n",
    "        out_csv=OUTPUT_FILE\n",
    "    )\n",
    "    print(f\"\\nClustering completed successfully!\")\n",
    "    print(f\"Results saved to {OUTPUT_FILE}\")\n",
    "    print(f\"DataFrame shape: {result_df.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during clustering: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
