{
  "strategy": "finetune_only",
  "experiment_name": "hpo_finetune_only_18",
  "token_encoding": "learnable",
  "embedding_dim": 64,
  "n_layers": 4,
  "kernel_size": 5,
  "n_filters": 256,
  "dense_layer_size": 256,
  "dropout": 0.5,
  "learning_rate": 9.225329954373328e-05,
  "batch_size": 256,
  "pretrain_epochs": 50,
  "finetune_epochs": 20,
  "finetune_lr_multiplier": 0.1,
  "augmentation_factor": 5,
  "vocab_size": 100,
  "maxlen": 200,
  "vocab_path": null
}