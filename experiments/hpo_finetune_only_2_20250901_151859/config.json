{
  "strategy": "finetune_only",
  "experiment_name": "hpo_finetune_only_2",
  "token_encoding": "learnable",
  "embedding_dim": 256,
  "n_layers": 5,
  "kernel_size": 5,
  "n_filters": 32,
  "dense_layer_size": 128,
  "dropout": 0.30000000000000004,
  "learning_rate": 0.005099675450291018,
  "batch_size": 128,
  "pretrain_epochs": 50,
  "finetune_epochs": 30,
  "finetune_lr_multiplier": 0.1,
  "augmentation_factor": 10,
  "vocab_size": 100,
  "maxlen": 200,
  "vocab_path": null
}