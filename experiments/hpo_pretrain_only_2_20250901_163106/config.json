{
  "strategy": "pretrain_only",
  "experiment_name": "hpo_pretrain_only_2",
  "token_encoding": "learnable",
  "embedding_dim": 64,
  "n_layers": 4,
  "kernel_size": 5,
  "n_filters": 64,
  "dense_layer_size": 512,
  "dropout": 0.30000000000000004,
  "learning_rate": 0.0016899896883567848,
  "batch_size": 256,
  "pretrain_epochs": 80,
  "finetune_epochs": 20,
  "finetune_lr_multiplier": 0.1,
  "augmentation_factor": 0,
  "vocab_size": 100,
  "maxlen": 200,
  "vocab_path": null
}