{
  "strategy": "pretrain_only",
  "experiment_name": "hpo_pretrain_only_6",
  "token_encoding": "learnable",
  "embedding_dim": 128,
  "n_layers": 2,
  "kernel_size": 3,
  "n_filters": 256,
  "dense_layer_size": 1024,
  "dropout": 0.5,
  "learning_rate": 0.00011530380748663843,
  "batch_size": 128,
  "pretrain_epochs": 70,
  "finetune_epochs": 20,
  "finetune_lr_multiplier": 0.1,
  "augmentation_factor": 0,
  "vocab_size": 100,
  "maxlen": 200,
  "vocab_path": null
}